# Frontend LLM backend configuration (build-time injected)
# Provide these via your deployment platform; do not commit real secrets.

# Base URL for the LLM backend (e.g., https://api.example.com)
ENV_LLM_API_URL=https://your-backend.example.com

# API key or token if your backend requires it (Authorization: Bearer <key>)
ENV_LLM_API_KEY=your-api-key-here

# Optional path for chat completions endpoint
ENV_LLM_CHAT_COMPLETIONS_PATH=/v1/chat/completions

# Optional request timeout (ms)
ENV_LLM_TIMEOUT_MS=20000
